2019-08-27 18:53:11 [scrapy.utils.log] INFO: Scrapy 1.7.2 started (bot: py_spiders)
2019-08-27 18:53:11 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.7.4 (default, Jul  9 2019, 18:14:44) - [Clang 9.0.0 (clang-900.0.39.2)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Darwin-16.7.0-x86_64-i386-64bit
2019-08-27 18:53:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'py_spiders', 'LOG_FILE': 'spider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'py_spiders.spiders', 'SPIDER_MODULES': ['py_spiders.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3493.3 Safari/537.36'}
2019-08-27 18:53:12 [scrapy.extensions.telnet] INFO: Telnet Password: 39aa529482edf405
2019-08-27 18:53:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-08-27 18:53:25 [twisted] CRITICAL: Unhandled error in Deferred:
2019-08-27 18:53:25 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/pymysql/connections.py", line 920, in connect
    **kwargs)
  File "/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py", line 727, in create_connection
    raise err
  File "/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 86, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.7/site-packages/scrapy/crawler.py", line 111, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/__init__.py", line 86, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.7/site-packages/scrapy/utils/misc.py", line 46, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/zz-med/caijihui/www/py_spiders/py_spiders/middlewares.py", line 12, in <module>
    from py_spiders.proxy import MyProxy
  File "/Users/zz-med/caijihui/www/py_spiders/py_spiders/proxy.py", line 24, in <module>
    class MyProxy():
  File "/Users/zz-med/caijihui/www/py_spiders/py_spiders/proxy.py", line 26, in MyProxy
    conn = pymysql.connect(DB_URL, DB_USER, DB_PASSWORD, DB_NAME, charset=DB_CHARSET)
  File "/usr/local/lib/python3.7/site-packages/pymysql/__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/pymysql/connections.py", line 699, in __init__
    self.connect()
  File "/usr/local/lib/python3.7/site-packages/pymysql/connections.py", line 967, in connect
    raise exc
pymysql.err.OperationalError: (2003, "Can't connect to MySQL server on '104.225.159.94' (timed out)")
